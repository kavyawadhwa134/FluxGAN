{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.16"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport numpy as np\nimport os\nfrom torch.cuda.amp import autocast\n\nclass Generator(nn.Module):\n    def __init__(self, noise_dim=100):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(noise_dim + 3, 256),\n            nn.LeakyReLU(0.2),\n            nn.Linear(256, 128),\n            nn.LeakyReLU(0.2),\n            nn.Linear(128, 3),\n            nn.Sigmoid()\n        )\n\n    def forward(self, z, conditions):\n        x = torch.cat([z, conditions], dim=1)\n        return self.net(x)\n\ndef load_for_inference(checkpoint_path, device='cpu'):\n    \"\"\"Load model and normalization parameters from checkpoint\"\"\"\n    checkpoint = torch.load(checkpoint_path, map_location=device)\n    \n    # Initialize generator\n    generator = Generator(noise_dim=100).to(device)\n    generator.load_state_dict(checkpoint['generator_state_dict'])\n    generator.eval()\n    \n    # Get normalization parameters\n    data_min = checkpoint['data_min']\n    data_max = checkpoint['data_max']\n    \n    return generator, (data_min, data_max)\n\ndef normalize(value, data_min, data_max):\n    \"\"\"Normalize using min-max scaling (matches training)\"\"\"\n    return (value - data_min) / (data_max - data_min)\n\ndef denormalize(value, data_min, data_max):\n    \"\"\"Denormalize using min-max scaling\"\"\"\n    return value * (data_max - data_min) + data_min\n\ndef generate(generator, norm_params, conditions, device='cpu'):\n    \"\"\"Generate predictions with optional conditioning\"\"\"\n    data_min, data_max = norm_params\n    input_norm = np.zeros(3)\n    mask = np.ones(3, dtype=bool)\n    \n    # Normalize input conditions\n    for i, key in enumerate(['Enrichment (%)', 'Flux', 'Burnup']):\n        if conditions[key] is not None:\n            input_norm[i] = normalize(conditions[key], data_min[i], data_max[i])\n            mask[i] = False\n    \n    with torch.no_grad(), autocast():\n        z = torch.randn(1, 100, device=device)\n        conditions_tensor = torch.FloatTensor(input_norm).unsqueeze(0).to(device)\n        output_norm = generator(z, conditions_tensor).cpu().numpy()[0]\n    \n    # Denormalize results\n    results = {}\n    for i, key in enumerate(['Enrichment (%)', 'Flux', 'Burnup']):\n        if mask[i]:\n            val = denormalize(output_norm[i], data_min[i], data_max[i])\n            status = \"(predicted)\"\n        else:\n            val = conditions[key]\n            status = \"(input)\"\n        results[key] = (val, status)\n    \n    return results\n\ndef format_small_values(value):\n    \"\"\"Format very small values appropriately\"\"\"\n    if isinstance(value, (float, np.floating)) and abs(value) < 1e-4:\n        return f\"{value:.10e}\"\n    return f\"{value:.4f}\"\n\nif __name__ == \"__main__\":\n    # Configuration\n    checkpoint_dir = '/home/jovyan/FluxGAN/plots/checkpoint'\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    \n    try:\n        # Find latest checkpoint\n        checkpoints = [f for f in os.listdir(checkpoint_dir) if f.endswith('.tar')]\n        latest = max(checkpoints, key=lambda x: int(x.split('_')[1].split('.')[0]))\n        checkpoint_path = os.path.join(checkpoint_dir, latest)\n        print(f\"Loading {checkpoint_path}\")\n        \n        # Load model\n        generator, norm_params = load_for_inference(checkpoint_path, device)\n        data_min, data_max = norm_params\n        \n        # Print normalization parameters for verification\n        print(\"\\nNormalization Parameters:\")\n        for i, key in enumerate(['Enrichment (%)', 'Flux', 'Burnup']):\n            print(f\"{key:>12}: Min={data_min[i]:.4f}, Max={data_max[i]:.4f}\")\n        \n        # Interactive prediction loop\n        while True:\n            print(\"\\nEnter conditions (leave blank to predict):\")\n            conditions = {}\n            for key in ['Enrichment (%)', 'Flux', 'Burnup']:\n                while True:\n                    inp = input(f\"{key}: \").strip()\n                    if not inp:\n                        conditions[key] = None\n                        break\n                    try:\n                        conditions[key] = float(inp)\n                        break\n                    except ValueError:\n                        print(\"Please enter a number or leave blank\")\n            \n            if all(v is None for v in conditions.values()):\n                print(\"At least one value required!\")\n                continue\n                \n            # Generate predictions\n            results = generate(generator, norm_params, conditions, device)\n            \n            # Display results\n            print(\"\\nResults:\")\n            for key, (val, status) in results.items():\n                formatted_val = format_small_values(val)\n                print(f\"{key:>12}: {formatted_val} {status}\")\n                \n    except KeyboardInterrupt:\n        print(\"\\nExiting...\")\n    except Exception as e:\n        print(f\"Error: {str(e)}\")","metadata":{"tags":[]},"execution_count":null,"outputs":[{"name":"stdout","text":"Loading /home/jovyan/FluxGAN/plots/checkpoint/checkpoint_1000.tar\n\nNormalization Parameters:\nEnrichment (%): Min=1.0007, Max=89.9858\n        Flux: Min=6.4532, Max=11.9977\n      Burnup: Min=0.0000, Max=0.0000\n\nEnter conditions (leave blank to predict):\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enrichment (%):  12\nFlux:  \nBurnup:  \n"},{"name":"stdout","text":"\nResults:\nEnrichment (%): 12.0000 (input)\n        Flux: 11.9977 (predicted)\n      Burnup: 1.4858083577e-08 (predicted)\n\nEnter conditions (leave blank to predict):\n","output_type":"stream"}],"id":"fb975a63-058a-44b2-bac0-11e0d13e6152"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"153a6ebb-a42c-4ed7-887f-d4743c161d21"},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport numpy as np\nimport pandas as pd\nimport os\nfrom IPython.display import display\n\n# Corrected Generator Model\nclass Generator(nn.Module):\n    def __init__(self, noise_dim=100):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(noise_dim + 3, 256),\n            nn.LeakyReLU(0.2),\n            nn.BatchNorm1d(256),  # BatchNorm added here to match checkpoint\n            nn.Linear(256, 128),\n            nn.LeakyReLU(0.2),\n            nn.BatchNorm1d(128),  # BatchNorm added here to match checkpoint\n            nn.Linear(128, 3),\n            nn.Sigmoid()  # Sigmoid for output\n        )\n\n    def forward(self, z, conditions):\n        x = torch.cat([z, conditions], dim=1)\n        return self.net(x)\n\n# Function to load the checkpoint\ndef load_checkpoint(checkpoint_path):\n    \"\"\"Load checkpoint with robust error handling\"\"\"\n    try:\n        checkpoint = torch.load(checkpoint_path, map_location='cpu')\n        \n        # Debug: show checkpoint contents\n        print(\"Checkpoint keys found:\", list(checkpoint.keys()))\n        \n        # Initialize generator\n        generator = Generator(noise_dim=100)\n        \n        # Try different possible state dict keys\n        state_dict_keys = ['generator_state_dict', 'generator', 'model_state_dict', 'state_dict']\n        loaded = False\n        for key in state_dict_keys:\n            if key in checkpoint:\n                # Load the state dict with strict=False to ignore missing keys\n                generator.load_state_dict(checkpoint[key], strict=False)\n                loaded = True\n                print(f\"Loaded generator weights from key: '{key}'\")\n                break\n        \n        if not loaded:\n            # Try loading direct state dict\n            try:\n                generator.load_state_dict(checkpoint, strict=False)\n                loaded = True\n                print(\"Loaded generator weights directly from checkpoint\")\n            except:\n                pass\n        \n        if not loaded:\n            raise KeyError(\"No generator state dict found in checkpoint\")\n        \n        generator.eval()\n        \n        # Get normalization parameters with defaults\n        data_min = checkpoint.get('data_min', [0, 0, 0])\n        data_max = checkpoint.get('data_max', [1, 1, 1])\n        \n        return generator, {\n            'data_min': data_min,\n            'data_max': data_max,\n            'scaler': {'feature_range': (0, 1)}  # Assuming MinMaxScaler\n        }\n        \n    except Exception as e:\n        raise ValueError(f\"Error loading checkpoint: {str(e)}\")\n\n# Function to generate flux and burnup for given enrichment values\ndef generate_flux_burnup(generator, checkpoint_info, enrichment_values):\n    \"\"\"Generate flux and burnup for given enrichment values\"\"\"\n    data_min = checkpoint_info['data_min']\n    data_max = checkpoint_info['data_max']\n    feature_range = checkpoint_info['scaler']['feature_range']\n    \n    results = []\n    \n    for enrich in enrichment_values:\n        # Normalize enrichment\n        if data_max[0] - data_min[0] == 0:  # Prevent division by zero\n            norm_enrich = 0.5\n        else:\n            norm_enrich = ((enrich - data_min[0]) / \n                          (data_max[0] - data_min[0])) * (feature_range[1] - feature_range[0]) + feature_range[0]\n        \n        # Create input with enrichment specified, others zero\n        input_norm = np.array([norm_enrich, 0, 0])\n        \n        with torch.no_grad():\n            z = torch.randn(1, 100)\n            conditions_tensor = torch.FloatTensor(input_norm).unsqueeze(0)\n            output_norm = generator(z, conditions_tensor).numpy()[0]\n        \n        # Denormalize outputs\n        def denormalize(val, idx):\n            return ((val - feature_range[0]) / \n                   (feature_range[1] - feature_range[0])) * (data_max[idx] - data_min[idx]) + data_min[idx]\n        \n        flux = denormalize(output_norm[1], 1)\n        burnup = denormalize(output_norm[2], 2)\n        \n        results.append([enrich, flux, burnup])\n    \n    return pd.DataFrame(results, columns=['Enrichment (%)', 'Flux', 'Burnup'])\n\n# Function to find the latest checkpoint in the directory\ndef find_latest_checkpoint(checkpoint_dir):\n    \"\"\"Find the latest checkpoint with proper error handling\"\"\"\n    if not os.path.exists(checkpoint_dir):\n        raise FileNotFoundError(f\"Checkpoint directory not found: {checkpoint_dir}\")\n    \n    checkpoints = [f for f in os.listdir(checkpoint_dir) if f.endswith('.tar')]\n    if not checkpoints:\n        raise FileNotFoundError(f\"No .tar checkpoint files found in {checkpoint_dir}\")\n    \n    # Sort by epoch number\n    def extract_epoch(f):\n        try:\n            return int(f.split('_')[-1].split('.')[0])\n        except:\n            return -1\n    \n    checkpoints.sort(key=extract_epoch)\n    latest = checkpoints[-1]\n    return os.path.join(checkpoint_dir, latest)\n\n# Main execution\nif __name__ == \"__main__\":\n    try:\n        # Configuration\n        checkpoint_dir = '/home/jovyan/FluxGAN/plots/checkpoint'\n        output_csv = os.path.join(checkpoint_dir, 'generated_flux_burnup.csv')\n        \n        # Define enrichment values\n        enrichment_values = np.array([\n            11.49, 3.5, 67.72, 17.36, 11.02, 69.62, 1.73, 42.41, 36.69, 18.87, \n            67.97, 63.78, 55.78, 20.99, 67.82, 60.98, 12.33, 56.87, 62.92, 5.0,\n            10.35, 2.11, 64.83, 4.93, 26.02, 76.18, 61.37, 62.78, 35.71, 35.29,\n            74.78, 48.16, 36.33, 62.18, 41.57, 32.45, 44.28, 29.37, 59.88, 31.42,\n            61.48, 43.76, 60.84, 29.65, 50.77, 14.72, 56.37, 18.69, 59.08, 52.48,\n            69.12, 2.92, 42.22, 62.93, 75.02, 14.64, 34.94, 9.09, 67.41, 49.67,\n            58.28, 49.66, 45.65, 30.15, 71.5, 52.89, 15.55, 29.94, 47.47, 78.25,\n            25.37, 3.81, 34.87, 20.77, 40.62, 63.6, 35.78, 47.05, 23.73, 51.87,\n            29.0, 63.33, 66.46, 20.4, 14.71, 11.55, 57.87, 55.93, 7.57, 61.82,\n            62.88, 70.7, 36.32, 75.0, 39.93, 54.81, 74.23, 24.26, 23.35, 79.74\n        ])\n        \n        # Find and load checkpoint\n        checkpoint_path = find_latest_checkpoint(checkpoint_dir)\n        print(f\"\\nLoading checkpoint from: {checkpoint_path}\")\n        \n        generator, checkpoint_info = load_checkpoint(checkpoint_path)\n        print(\"\\nGenerator successfully loaded!\")\n        print(f\"Data min: {checkpoint_info['data_min']}\")\n        print(f\"Data max: {checkpoint_info['data_max']}\")\n        \n        # Generate predictions\n        print(\"\\nGenerating flux and burnup values...\")\n        results_df = generate_flux_burnup(generator, checkpoint_info, enrichment_values)\n        \n        # Save and display results\n        results_df.to_csv(output_csv, index=False)\n        print(f\"\\nResults saved to: {output_csv}\")\n        print(\"\\nFirst 5 predictions:\")\n        display(results_df.head())\n        \n    except Exception as e:\n        print(f\"\\nError occurred: {str(e)}\")\n        print(\"\\nTroubleshooting steps:\")\n        print(\"1. Verify the checkpoint directory exists and contains .tar files\")\n        print(\"2. Check the checkpoint contents with:\")\n        print(f\"   import torch; print(torch.load('{checkpoint_path}', map_location='cpu').keys())\")\n        print(\"3. Ensure the Generator architecture matches your training code\")\n","metadata":{"trusted":true,"tags":[]},"execution_count":23,"outputs":[{"name":"stdout","text":"\nLoading checkpoint from: /home/jovyan/FluxGAN/plots/checkpoint/checkpoint_10.tar\nCheckpoint keys found: ['epoch', 'generator_state_dict', 'discriminator_state_dict', 'optimizer_G_state_dict', 'optimizer_D_state_dict', 'data_min', 'data_max']\nLoaded generator weights from key: 'generator_state_dict'\n\nGenerator successfully loaded!\nData min: [1.00073484e+00 6.45316091e+00 1.48580836e-08]\nData max: [8.99858114e+01 1.19977241e+01 4.58969245e-08]\n\nGenerating flux and burnup values...\n\nResults saved to: /home/jovyan/FluxGAN/plots/checkpoint/generated_flux_burnup.csv\n\nFirst 5 predictions:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   Enrichment (%)       Flux        Burnup\n0           11.49   9.186839  3.255059e-08\n1            3.50  10.010794  2.756544e-08\n2           67.72   8.791043  2.280178e-08\n3           17.36   9.370809  2.538571e-08\n4           11.02   9.563942  3.368628e-08","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Enrichment (%)</th>\n      <th>Flux</th>\n      <th>Burnup</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11.49</td>\n      <td>9.186839</td>\n      <td>3.255059e-08</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.50</td>\n      <td>10.010794</td>\n      <td>2.756544e-08</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>67.72</td>\n      <td>8.791043</td>\n      <td>2.280178e-08</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>17.36</td>\n      <td>9.370809</td>\n      <td>2.538571e-08</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11.02</td>\n      <td>9.563942</td>\n      <td>3.368628e-08</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"id":"d67a7670-3eb6-48e3-b423-0aa9513969e0"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"b3a52f67-66a8-4269-bee8-d1df059154eb"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"1108583b-4096-48b2-bcd6-2a8dd778fa9d"}]}
